# C++20 modules and Boost: deep dive
:source-highlighter: highlightjs
:toc: left
Rubén Pérez (@anarthal)

This document is a follow-up to https://anarthal.github.io/cppblog/modules[my previous post on C++20 modules and Boost]. Following the generated debates, we will cover:

* A benchmark about compile-times when re-building code consuming modules. (TODO: link)
* Additional information on which modularization strategies work cross-platform and which ones don't, together with their CMake implications. (TODO: link).
* A mental model for Boost libraries with separate compilation. (TODO: link)
* Unit testing implications. (TODO: link)

Reading (TODO: link) the previous post is strongly recommended. With the information in this post, we (the Boost author community) should have enough information to make an informed decision about module support in Boost (TODO: link).

## Re-build time benefits

In https://anarthal.github.io/cppblog/modules#_measuring_build_time_benefits[the previous post], we benchmarked build times for an Asio-based server. We used the modular version of `libc++` and a modular standalone Asio prototype to measure build times, varying the number of translation units. We observed very small benefits, increasing with the number of TUs.

These results included the time required to build Asio and the standard library modules. This is what you'd encounter when doing a clean build in a CI system. But what benefits would we see during local development, where the Asio and `std` modules have already been built? Here are the results:

[cols="1,1,1"]
|===
| Number of re-built translation units | Build time (modules) | Build time (headers)

|1 TU    |02.584s     |04.655s
|2 TU    |03.027s     |05.593s
|3 TU    |03.703s     |06.632s
|4 TU    |05.849s     |11.198s
|5 TU    |06.897s     |12.280s
|6 TU    |07.331s     |13.197s
|7 TU    |10.043s     |17.589s
|1 TUerr |00.850s     |03.114s
|===

The modular version has considerable gains here, with a consistent ~45% reduction over the header version.

Benchmark conditions:

* clang-19 (Linux)
* Debug CMake build (note that the clean build measurements were performed in a Release build - debug seems more appropriate to measure what happens during local development).
* Building with 3 cores  to measure the effects of parallelism.
* Modular builds use Asio and the standard library as modules. The time to build such modules is _not_ included in the benchmark.
* The reported time includes the time elapsed by CMake re-scanning module dependencies for the affected translation units, which is usually not significative.

What if we hit build but had an error in a translation unit? The compiler won't be able to perform any code generation, so the results are even better:

[cols="1,1"]
|===
| Build time (modules) | Build time (headers)
|00.850s     |03.114s
|===

This means that errors are reported almost instantly. The measurement was taken by attempting to call an existing function with incorrect arguments at the end of the translation unit.

Takeaway: *modules can make the local development feedback loop faster*.

## How to modularize a library: the pointy edges

The promising `export using` technique I talked about in https://anarthal.github.io/cppblog/modules#_how_to_modularize_a_library[my previous post] is unfortunately limited to clang. There are two issues which prevent its use under MSVC. 

### Mixing standard includes and imports is problematic

This is true even if the mix happens in different translation units, as long as they interact via `import`. For instance, this is problematic:

* We modularize the Asio library non-intrusively, using the approach described above. As a result, the `asio` module consumes the standard library via `#include`.
* A user consumes both `asio` and the `std` modules via `import`.

As confirmed by a Microsoft developer, this is known to cause problems. While the standard mandates that this shouldn't be the case, fixing it may take some time yet, so we can't rely on it.

This very much likely applies to our code, too - if we mix including and importing the same Boost libraries, we're likely going to run into trouble.

### Exporting template specializations

Consider this code in the Asio library:

[source,cpp]
----
namespace std {

template <> struct is_error_code_enum<asio::error::basic_errors>
{
  static const bool value = true;
};

}
----

If we attempt a non-intrusive approach like the following:

[source,cpp]
----
// asio.cxx - defines how to build Asio as a module so it can be imported
module;

#include <asio.hpp>

export module asio;

namespace asio::error {
export using asio::error::basic_errors;
// ...
}
----

What does the following client code see?

[source,cpp]
----
import asio;
import std;

static_assert(std::is_error_code_enum<asio::error::basic_errors>::value);
----

* Under clang, the assertion succeeds, as the template specialization gets exported from the `asio` module.
* Under MSVC, the assertion fails. Apparently, the specialization is not considered to be https://eel.is/c++draft/module.global.frag[decl-reachable] from the module purview and thus discarded.

I don't know which behavior is correct. But this implies that headers need to be included within the module purview, which requires additional effort. This is the approach Matt Borland followed when he modularized Boost.Math.

### MSVC SEH causes compiler errors

Windows-specific code using the `__try`/`__catch` constructs, present in Asio, causes trouble. This seems to be https://developercommunity.visualstudio.com/t/Using-__try-in-an-inline-function-in-a-h/10186252[a bug in MSVC] which never got deployed.

### Exporting macros

Modules don't export macros. You need to use traditional include files to do that. Boost has many useful macros that may be required internally and by users:

* Libraries like https://www.boost.org/doc/libs/1_85_0/libs/assert/doc/html/assert.html[Boost.Assert] or https://www.boost.org/doc/libs/1_85_0/libs/config/doc/html/index.html[Boost.Config] are almost just macros. I propose not creating any modules for these, but just including them as you'd do with `<assert.h>`. Some work is required to ifdef-out standard includes when present.
* Some libraries expose macros indicating the presence of platform-specific features. For instance, the `asio::local::stream_protocol` class is only present if `ASIO_HAS_LOCAL_SOCKETS` is defined. `if constexpr` is probably not suitable for this task (see https://godbolt.org/z/n7e5ceTxY[this] and https://godbolt.org/z/1TboMnGWT[this] Godbolts). We'd need to refactor `config.hpp` headers for such libraries to provide the relevant macros.
* Other libraries expose a combination of macros and types, like Boost.Test. Non-trivial refactoring is required to make these work.

Note that using `#include <version>` looks safe on all platforms, even when using `import std`.

### Wrapping up

* Modularizing requires intrusive changes: ifdef-ing out includes, marking names as exported and potentially refactoring some headers to export certain macros.
* If a Boost library X consumes another Boost library Y, it will `import boost.Y`, and possibly include a Y header, if it requires some macros.

## Compiled libraries

We have two approaches for compiled libraries:

. Adapt their implementation (`.cpp` files) so they are conditionally built and consumed using modules.
. Keep their implementation files as they are, and provide modular code for the interface (as we'd do with header-only libraries).

The second approach seems the most suitable one for us, since it'd make our modules compatible with the binary libraries we generate today. Our libraries would be built using `b2` as they are today, and would also be importable.

How does `export` interact with `__declspec(dllexport)` and similar constructs? The following mental model may be useful:

* Think of `export` a construct for the compiler, affecting declarations and definitions.
* Think of `__declspec(dllexport)` and friends as constructs for the linker, affecting symbols in object files.

In a compiled library, you'd:

* Mark as both `export` and `__declspec(dllexport)` compiled functions that should be visible by importers.
* Mark as `__declspec(dllexport)` compiled functions that are considered implementation details, and are not to be called by the end user.
* Mark as `export` inline functions and templates that may be called by the end user.

Modularizing compiled libraries is almost identical to doing so for header-only libraries (with some details). See (TODO: link) this example as a proof-of-concept for the charconv library.

Note that this seems to work fine even if the library includes the standard library in its implementation. This makes sense because the library's translation units are not seen by the compiler when importing, but only by the linker.

## CMake

My previous post proposed providing https://anarthal.github.io/cppblog/modules#_consuming_boost_using_modules[a CMake function] to our users to build Boost modules. This works fine for modules without dependencies, but falls short if we internally consume Boost libraries using `import`.

### Using IMPORTED module targets

I've https://discourse.cmake.org/t/advice-on-c-20-modules-boost/10641[reached the CMake team for help]. Their recommended method is to build 

* Problematic: when a user needs to consume a library using `import boost.beast`, it needs to build the Beast module, plus all its modular dependencies, which may be many. This assumes one module per Boost library (roughly speaking). Just providing the module code doesn't help the user, as building it would require tracking dependency chains they don't care about.
* Revisiting imported targets for modules in CMake: they build once in the source project when they export, then in the target project when they are imported. Together with dependencies. This is a step in the correct direction, but currently just use the same settings used by the source project, and don't take the consumer's options in consideration. Result: very high chance of incompatible BMIs.
* I've reached the CMake team for help. They plan on extending the modules as imported targets to partially cover this, and building modules (and dependents) according to the consumer's configuration. But this doesn't have an ETA - probably this year.
* The solution doesn't take into account possible configuration macros we offer - take ASIO_DISABLE_THREADS (or one of the hundred other option macros) as example.
* Workaround: a user may set configuration macros by setting the `IMPORTED_CXX_MODULES_COMPILE_DEFINITIONS` definitions on the imported module target. For instance:

set_property(TARGET asio APPEND PROPERTY IMPORTED_CXX_MODULES_COMPILE_DEFINITIONS ASIO_DISABLE_THREADS)

But note that this allows a user to build a single version of our modules. If they need different configurations in the same project, then they're fucked up. On the bright side, this may help prevent ODR violations.

* As an alternative, we can write CMake machinery, equivalent to the function in the previous post (TODO: link), which knows about our dependency chains and adds the required modules on demand. This is more flexible, but also much much more work, and more clunky for users (a probably small use case impacts the usability of a bigger one).
* When relying on imported targets, CMake requires the modules to be packaged as a library. This is a dummy library containing an object file that never gets used - see https://discourse.cmake.org/t/header-only-libraries-and-c-20-modules/10680. This can be circumvented if we write functions ourselves by using an OBJECT library.



## Testing the implementation

* If we are to provide module code for Boost, we need a way to test its correctness before shipping it to users.
* "The module builds" is not a strong enough check. Asio builds but is inherently flawed on MSVC because __try. You may forget to export public functions.
* The most reliable way is porting the library's test suite to use modules, in a similar way as we're proposing headers. Extra work, but should be able to detect real problems. This would be called from the CMake build when using some option, or from the B2 build if B2 finally implements module support.
* We'd also need a flow to verify the generated CMake files include correct module support, with all dependencies correctly set. This would be similar to the "CMake consumer tests" we currently have in most libraries.

## Moving forward

* We now know the benefits and implications of providing modular consumption for the current Boost project.
* We need to make a decision, as a community, whether we want to move this forward or leave it here. I won't push it if the author community is against it.
* Users, we want your feedback - would this be something you'd use?
* I am up to perform this work, but requires authors to review and merge PRs, and probably some aid during design from the core Boost maintainers (those who know the infrastructure).