# Boost.Asio properties

## Outstanding work tracking

## Submitting a function to an executor: dispatch(), post() and defer()

As you may know, these functions are the preferred way to submit
functions to an executor. In their simplest form, they take a nullary completion
token as argument:

[code,cpp]
----
void f() {
    printf("I'm a function\n");
}

int main() {
    asio::io_context ctx;
    asio::dispatch(asio::bind_executor(ctx.get_executor(), f));
    ctx.run();
}
----

Any of these three functions guarantee that `f` will be executed
**on the executor associated to `f`**. While the three functions
difer on how `f` is scheduled, all of them provide this guarantee.

## The default associated executor is the `system_executor`

Does this code compile?

[code,cpp]
----
void f() {
    printf("I'm a function\n");
}

int main() {
    asio::dispatch(f);
}
----

We're submitting `f` for execution, but `f` doesn't have an associated executor.

It does build, and `f` will get executed. That's because if an object doesn't have
an associated executor, the system executor (`asio::system_executor`) is used.
The system executor doesn't provide guarantees on which thread your function
will be run on, so this must be used with caution to avoid data races.

## The difference between post() and dispatch()

Many other blog posts talk about this, so let's be brief. `defer()` is almost never used,
so let's focus on the other two.

Let's stay concrete and stick to `io_context`. When invoked from a thread that is **not**
calling `io_context::run()`, they both queue the submitted function for execution:

[code,cpp]
----
void f() {
    printf("I'm a function\n");
}

int main() {
    asio::io_context ctx;

    // Doesn't call f immediately, queues it
    asio::dispatch(asio::bind_executor(ctx.get_executor(), f));

    // Doesn't call f immediately, queues it too
    asio::post(asio::bind_executor(ctx.get_executor(), f));

    // Executes f twice
    ctx.run();
}
----

When called from a thread that is calling `run()`, `post()` will queue the
function (as in the previous case), but `dispatch()` will run the function
immediately, before `dispatch()` returns:

[code,cpp]
----

void f() { printf("Function f\n"); }
void g() { printf("Function g\n"); }

int main()
{
    asio::io_context ctx;
    auto ex = ctx.get_executor();

    // Submit the lambda for execution. Invoked as part of run()
    asio::post(asio::bind_executor(ex, [ex] {
        printf("Lambda entry\n");

        // Since this lambda is running from a thread calling run(),
        // if will be invoked immediately, as part of the dispatch call
        asio::dispatch(asio::bind_executor(ex, f));

        // However, g will not be executed as part of the lambda. It will be queued
        // and run after the lambda returns
        asio::post(asio::bind_executor(ex, g));

        printf("Lambda exit\n");
    }));

    ctx.run();
}

// Prints:
//   Lambda entry
//   Function f
//   Lambda exit
//   Function g
----

## Networking TS executors vs. proposed standard executors

You may have come accross these terms when reading Asio docs. If you consult
`io_context::executor` docs, you will encounter the following member functions:

* `post()`, `dispatch()`, `defer()`, `on_work_started()` and `on_work_finished()`.
  Executors with these functions fulfill the requirements of networking TS executors.
  This is an older, simpler model.
* `execute()`, `query()` and `require()`. These functions implement the proposed standard executors,
  though a newer, more complex system of properties.

Both models co-exist in Asio. Some functions and classes work only with standard executors
(e.g. `any_io_executor`), while others work with both. In general, Asio prefers using
the standard executor model vs. the networking TS model, if both are available.

Note that we've been calling the `asio::post()` standalone function, **not the `io_context::post()`
member function**. Actually, `asio::post()` **will not call `io_context::post()`** as part
of its implementation - we'll delve deeper in further sections.

## The property system

So how are `asio::post()` and `asio::dispatch()` implemented? They use
the new property system.

Recall that executors are lightweight handles to execution contexts.
In our case, `io_context` is an execution context, while `io_context::executor`
is a lightweight, cheap-to-copy handle that allows submitting work to the underlying
`io_context`.

Under this new system, executors implement a single function, `execute()`. Like
the old `post()` and `dispatch()` member functions, it accepts a function without
arguments, which will be submitted for execution.

`io_context::executor` stores internally some flags that dictate what "executing a function"
means. For instance, one of the flags enables executing the passed function as part of `execute()`.
If the flag is set, `execute()` behaves like `dispatch()`, otherwise, it behaves like a `post()`.

The flags I've been talking about are exposed to the user as properties of an executor.
This is a complex, extensible system that can represent much more than flags.

To set a property of an executor, call `asio::require(ex, prop)`, which returns
a new executor with `prop` set. For instance:

[code,cpp]
----
void f() { printf("Function f\n"); }
void g() { printf("Function g\n"); }

int main()
{
    asio::io_context ctx;
    auto ex = ctx.get_executor();

    // Submit the lambda for execution. Invoked as part of run()
    asio::post(asio::bind_executor(ex, [ex] {
        printf("Lambda entry\n");

        // Executes f through ex. If no property is set, execute()
        // behaves like dispatch(), so f will be run immediately, as part of execute()
        ex.execute(f);

        // Create a copy of ex, setting the blocking property to never.
        // This will make execute() behave like post()
        auto ex2 = asio::require(ex, asio::execution::blocking.never);

        // g will not be executed as part of the lambda. It will be queued
        // and run after the lambda returns
        ex2.execute(g);

        printf("Lambda exit\n");
    }));

    // Executes f twice
    ctx.run();
}

// Prints:
//   Lambda entry
//   Function f
//   Lambda exit
//   Function g
----

`asio::prefer(ex, prop)` behaves similarly to `require`, but does not guarantee
that the returned executor will have the property set (it just indicates a preference).
`asio::query(ex, prop)` retrieves the value of a property.

There is **a lot** of template machinery behind this system to allow for customization
points and type-safety. For instance, `asio::require(ctx.get_executor(), asio::execution::mapping.new_thread)`
(which asks the executor to launch every passed function into its own new thread)
will fail to compile, since `io_context` can't satisfy this. Error messages can be cryptic, though.

### The `blocking` property

As we've seen before, this property controls whether the function passed to `execute()`
can be run immediately, as part of `execute()`, or must be queued for later execution.
Possible values are:

* `asio::execution::blocking.never`: never run the function as part of `execute()`.
  This is what `asio::post()` does.
* `asio::execution::blocking.possibly`: the function may or may not be run as part of `execute()`.
  This is the default for `io_context::executor`, and what `asio::dispatch()` does.
* `asio::execution::blocking.always`: the function is always run as part of `execute()`.
  This is not supported by `io_context::executor`.

### The `relationship` property

TBC